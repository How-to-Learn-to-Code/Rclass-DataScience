{"title":"Practicing on Real-World Data","markdown":{"yaml":{"title":"Practicing on Real-World Data","subtitle":"Project Management, Day 2","authors":"Lorrie He, Matthew Sutcliffe","format":{"html":{"toc":true}},"output":{"html_document":null},"editor":"visual"},"headingText":"read in data for later","containsRefs":false,"markdown":"\n\n```{r setup, echo=FALSE}\nebola0 <- read.table(\"project-day-2-files/datasets/ebola.csv\", header = TRUE, sep = \",\")\ntemps0 <- read.table(\"project-day-2-files/datasets/temperatures.csv\", header = TRUE, sep = \",\")\navida0 <- read.table(\"project-day-2-files/datasets/avida/avida_wildtype.csv\", header = TRUE, sep = \",\")\n\nknitr::opts_chunk$set(echo=FALSE, digits = 3)\n```\n\n## Final class!\n\n::: {.callout-note collapse=\"true\"}\n## Instructor notes\n\n::: panel-tabset\n### 1. Prep & lesson goals\n\nThe idea of this lesson is to give students an opportunity to really stretch their wings and work independently, so the material is pretty open-ended. We have prepared a few datasets for them to practice working on, as well as additional structure to try to support students at different science/coding comfort levels, so students can decide if they want to do the whole workflow themselves (develop questions, analysis, figs), do only parts of it (develop their own analysis and figs), or just practice the coding (recreate a figure from the raw data).\n\nThat said, there will be a bit of prep work on your end for this class because this is so open-ended: would strongly encourage being somewhat familiar with the background and data overview sections for each dataset before class, as well as the pre-filled project templates. These shouldn't be terribly tricky datasets for instructors to work with, and you don't really need to understand the underlying science (except maybe for the Avida data): just know enough that you could tell a student \"that figure/analysis makes sense and is informative\", have some intuition of what is making their code break, etc.\n\nIdeally, students can just read up on what each dataset contains, come up with questions, and happily work their way through it and make some beautiful figures with no issues :-) That said, the ultimate goal for this lesson is that students will leave today with a repo containing a mostly done analysis (data, cleaning script, analysis script, final figs, etc), and maybe have an opportunity to test their R vocab knowledge by practicing their R googling skills... ðŸ˜\n\n### 2. Suggested lesson \"script\"\n\ntbh, you can be pretty off-script for this lesson (i.e. use different datasets, create different analyses, etc): again, the goal is just for students to really synthesize the lessons, put them into practice, and try to work independently -- at base, stress this aspect to them. That said, these datasets were chosen because they should hopefully be easy enough to understand but tricky enough to challenge them a little at this point in their learning.\n\nOtherwise, if you want a script, probably at least emphasize the following points/make sure everyone is on the same page about these things before letting them off on their own:\n\n-   **Final class!**\n    -   Briefly recap previous class, emphasize today is a very open-ended synthesis/capstone day and they should try to leave with something \"finished\"\n    -   Mention project template script\n-   **Datasets**\n    -   There are 3 datasets: each mentions suggested skills to practice, background info, data overview, and analysis hints\n    -   Students can be as independent or not as they want, but you *do* have some prepared examples that you will be more familiar with (but the examples are basically all tidyverse, fyi ðŸ˜…)\n    -   Some of these datasets def require some external code they haven't learned in this class to manage more easily: see the \"hints\" sections. Sometimes there are very specific, heavily-handed described suggestions and sometimes there are just vague suggestions (aka go google it)\n\n### 3. Tips & ideas for running the lesson\n\nTo make the work easier on you, you could have people work in pairs (but in their own repos). You could maybe have them work in larger groups/have everyone do the same analysis, but it might feel too much like data viz day 2...\n\nThere will be some pre-filled project templates in the folder that goes through the whole process for 1 easy and 1 hard question for each dataset (which will stress the specific \"skills to practice\" for each dataset; primarily, these are focused on tidyverse approaches): you should look at these before class. These are effectively mini-lessons on their own, but hopefully straightforward enough for a student to follow along on their own (get 'em some practice for reading through elaborate stackoverflow answers ðŸ¥¹)\n\nYou can reiterate to the class that for those who want a bit more structure/support, you will be most familiar with the details for the prepared material (i.e. they should try to recreate those figs/scripts on their own because you'll have the \"answer\"). But ultimately, it's up to you for how much you want to balance giving them independence with the inevitability of dealing with 1 million questions simultaneously ðŸ«¡\n\nMisc comments:\n\n-   re: how the datasets were ranked: basically from less to more \"you might want to use code you haven't seen before to wrangle it.\" The \"external code\" was included so students can have a resource for when they inevitably encounter tricky wrangling situations... also, so they can practice googling!\n\n-   re: what makes questions \"easier\" vs \"harder\", those divisions are mostly based off how much wrangling effort/function wizardry is involved. There any many ways to answer the questions. And obviously, those aren't the only questions you can ask for the datasets, so feel free to come up with more.\n:::\n:::\n\nIn the previous class, you completed the following steps:\n\n> 1.  Created a GitHub account.\n>\n> 2.  Linked your GitHub account with your Longleaf account.\n>\n> 3.  Created and pushed your first repository to GitHub.\n\nToday, now that you've been through the entire course, we want to reinforce some of the skills that you've learned by having you apply your knowledge to several existing datasets and go through the wrangling, analysis, and visualization process independently as much as you can. By the end of this lesson, you should have a GitHub repo containing scripts for wrangling and analysis for at least one of these datasets that you can show to others (or at least have as reference for your future self).\n\nFor each of these datasets (or as many as time allows), we'd like you to do some basic analysis, including the following steps:\n\n> 1.  Create a directory for the analysis of this dataset, using best practices discussed in the previous class.\n>\n> 2.  Load in the data.\n>\n> 3.  Perform some initial data exploration (What are the rows? What are the columns? How many samples does this dataset have? etc.)\n>\n> 4.  Identify at least 1 research question that you could try to answer with this dataset.\n>\n> 5.  Format the data in a way that allows for this analysis.\n>\n> 6.  Visualize the data in helpful ways to answer your question.\n>\n> 7.  Make your code reproducible by using GitHub.\n\nTo help with your analyses, we have included a **template document** outlining these steps that you are welcome to use.\n\n## Datasets\n\nThe csvs are available under the `data` folder (or wherever it'll be moved to). We have provided links to data that is publicly available for download, as well as some related publications that may give you more information about the data.\n\nThese datasets were chosen because we thought they represented a good variety in the different kinds of wrangling and visualization challenges you might encounter with your own data in the futur: we have highlighted a few specific R skills that some of these datasets were meant to challenge you on.\n\n::: callout-note\nThe datasets are presented roughly in order of increasing wrangling complexity. Though you should have most of the basic skills you need to wrangle and analyze these datasets, we have specifically provided the code to aid you in certain wrangling tasks for some of the later datasets: see the \"Analysis ideas and hints\" callout for each dataset.\n:::\n\nFor each dataset, we have provided a description of the research question/data collection methods, metadata, and the first few lines of each dataset. Read through these descriptions and work on the dataset you find most interesting. Feel free to work with a partner!\n\n::: {.callout-tip title=\"But I thought this was HTLTCode, not HTLTScience!\"}\nTo get the most out of today's activities, we highly encourage you to practice going through the whole data analysis workflow as independently as you can, developing your own research questions and analysis ideas.\n\nThat said, we have prepared some example research questions and figures for each dataset to get everyone started, so you can decide if you'd rather focus more on coding or science-ing for each dataset. These questions are split into \"easier\" and \"harder\" coding challenges, with \"harder\" challenges generally involving slightly more wrangling.\n\nThus, based on your comfort level, you can decide how much of the data analysis workflow you want to try independently today:\n\n1.  Recreate our figures\n2.  Develop your own analysis and figures to answer our research questions\n3.  Develop your own research questions, analysis, figures\n:::\n\n### AVIDA digital evolution dataset\n\n[Related publications](https://avida-ed.msu.edu/digital-evolution/)[^class8-1]\n\n[^class8-1]: In particular, see [Lenski et al. (2003)](https://www.nature.com/articles/nature01568) and [Smith et al. (2016)](https://link.springer.com/article/10.1186/s12052-016-0060-0).\n\n**Skills to practice:** working with multiple datasets, pivoting\n\n**Background:** The following data was generated using [Avida-ED](https://avida-ed.msu.edu/avida-ed-application/), an online educational application that allows one to study the dynamics of evolutionary processes. Digital, asexually-reproducing organisms known as \"Avidians\" can be placed into something akin to a virtual Petri dish to evolve in, and one can manipulate parameters such as mutation rate, resource availability, and dish size to study how those factors affect the evolution of the population.\n\nYour friend needs your help to analyze their AVIDA-Ed data. They designed a series of experiments around a mutant Avidian that gets an energy bonus when the sugar \"nanose\" is present and a wildtype Avidian that does not. They wanted to see how competition and resource availability affect the population dynamics of these Avidians.\n\nYour friend grew either the wildtype only, mutant only, or both populations together (competition) in the following 3 environments:\n\n-   Minimal (no additional sugars present)\n\n-   Selective (only nanose present)\n\n-   Rich (nanose and additional sugars present)\n\n```{r dplyr_syntax,echo=FALSE, fig.align = 'center', out.width = \"65%\", fig.cap = \"Avida experiment setup\"}\nknitr::include_graphics(\"project-day-2-files/figs/avida-expt.png\")\n```\n\nHelp your friend get started with some of the exploratory data analysis. *What interesting patterns can you find between genotype, competition, and resource availability?*\n\n::: {.callout-note collapse=\"true\" title=\"Data overview\"}\n::: panel-tabset\n#### Data preview\n\nData for `avida_wildtype.csv` shown only:\n\n```{r}\nknitr::kable(head(avida0))\n```\n\n#### Column metadata\n\n| Column                      | Type      | Description                                                                       | Values                                                       |\n|-------------|-------------|---------------------------|-------------------|\n| `update`                    | integer   | Time elapsed                                                                      | Ranges 0-300                                                 |\n| `condition`                 | character | Testing conditions (single population or competition)                             | Based off csv: `wildtype-only`, `mutant-only`, `competition` |\n| `media_avg-fitness`         | numeric   | Average individual reproductive success in specified media                        | Ranges 0-1                                                   |\n| `media_avg-offspring.cost`  | numeric   | Average individual reproductive cost in specified media                           |                                                              |\n| `media_avg-energy-acq-rate` | numeric   | Average individual rate of energy acquisition from environment in specified media |                                                              |\n| `media_pop-size`            | integer   | Population size in specified media                                                | Ranges 0-900                                                 |\n\nAll population measurements were determined for `minimal`, `selective`, and `rich` media.\n:::\n:::\n\n::: {.callout-tip collapse=\"true\" title=\"Analysis ideas and hints\"}\n::: panel-tabset\n#### Analysis hints\n\n-   Which files have the pieces of data you need? Do you need to mix-and-match anything?\n\n-   The data could be \"tidier\"...\n\n#### Example questions\n\nUse these questions to develop your own, or answer them as-is. These is no \"single\" or \"correct\" way to answer to these questions, and you can refine or broaden the scope of these questions as needed.\n\n**Bolded** questions have an accompanying figure and code.\n\n------------------------------------------------------------------------\n\nEasier\n\n-   **How does population size change over time for the wildtype (or mutant) in different medias?**\n-   What is the relationship between fitness and offspring cost in competition conditions in different medias?\n\nHarder\n\n-   **How does the change in fitness over time compare between different treatment conditions and media types?**\n-   Which media type allows for the most maximal performance of the wildtype? The mutant? Competition conditions?\n\n#### Example figures\n\n**Easier: How does population size change over time for the wildtype (or mutant) in different medias?**\n\n![](project-day-2_files/figs/avida-easy.png){width=\"75%\"}\n\n**Harder: how does the change in fitness over time compare between different treatment conditions and media types?**\n\n![](project-day-2_files/figs/avida-hard.png){width=\"75%\"}\n:::\n:::\n\n### Western Africa Ebola public health dataset\n\n[Data source](https://www.kaggle.com/datasets/imdevskp/ebola-outbreak-20142016-complete-dataset)\n\n**Skills to practice:** working with dates, pivoting\n\n**Background:** The Western African Ebola virus (EV) epidemic of 2013-2016 is the most severe outbreak of the EV disease in history. It caused major disruptions and loss of life, mainly in the republics of Guinea, Liberia, and Sierra Leone.\n\n*How might you represent the dynamics of this outbreak?*\n\n::: {.callout-note collapse=\"true\" title=\"Data overview\"}\n::: panel-tabset\n#### Data preview\n\n```{r}\nknitr::kable(head(ebola0))\n```\n\n#### Column metadata\n\n| Column                                                       | Type      | Description                     | Values     |\n|--------------------------------|-------------|---------------|-------------|\n| `Country`                                                    | character | Country of report               |            |\n| `Date`                                                       | character | Date of report                  | YYYY-MM-DD |\n| `Cumulative.no..of.confirmed..probable.and.suspected.cases`  | numeric   | Cumulative number till this day |            |\n| `Cumulative.no..of.confirmed..probable.and.suspected.deaths` | numeric   | Cumulative number till this day |            |\n:::\n:::\n\n::: {.callout-tip collapse=\"true\" title=\"Analysis ideas and hints\"}\n::: panel-tabset\n#### Analysis hints\n\n-   This dataset contains data for other countries besides the three named above. For simplicity, you may want to focus on only those three regions.\n\n-   The current format of the data isn't \"tidy\"...\n\n-   You can use `format()` to extract specific parts of a date object: e.g. if `x` is a date object with the format `%Y-%m-%d`, you can get the year with `format(x, \"%Y\")`.\n\n#### Example questions\n\nUse these questions to develop your own, or answer them as-is. These is no \"single\" or \"correct\" way to answer to these questions, and you can refine or broaden the scope of these questions as needed.\n\n**Bolded** questions have an accompanying figure and code.\n\n------------------------------------------------------------------------\n\nEasier\n\n-   **How many cases and deaths in total were recorded by each country from 2014-2016?**\n-   For a specific year, how did the number of cases and deaths change over time for each country?\n\nHarder\n\n-   **By country, how did the average number of cases and death change each year?**\n-   Are there any seasonal patterns in the average cases and deaths?\n\n#### Example figures\n\n**Easier: How many cases and deaths in total were recorded by each country from 2014-2016?**\n\n![](project-day-2_files/figs/ebola-easy.png){width=\"75%\"}\n\n**Harder: By country, how did the average number of cases and death change each year?**\n\n![](project-day-2_files/figs/ebola-hard.png){width=\"75%\"}\n:::\n:::\n\n### Heat exposure in Phoenix, Arizona ecological dataset\n\n[Data source](https://data.sustainability-innovation.asu.edu/cap-portal/metadataviewer?packageid=knb-lter-cap.647.2) \\| [Related publication](https://doi.org/10.1016/j.envint.2020.106271)\n\n**Skills to practice:** parsing strings, dealing with `NA` values\n\n**Background:** Exposure to extreme heat is of growing concern with the rise of urbanization and ongoing climate change. Though most current knowledge about heat-health risks are known and implemented at the neighborhood level, less is known about individual experiences of heat, which can vary due to differences in access to cooling resources and activity patterns.\n\nTo further investigate, the Central Arizona-Pheonix Long-Term Ecological Research Program [(CAP-LTER)](https://sustainability-innovation.asu.edu/caplter/) recruited participants from 5 Pheonix-area neighborhoods to wear air temperature sensors that recorded their individually-experienced temperatures (IETs) as they went about their daily activities.\n\n*What kind of relationships can you find between individual activity and neighborhood?*\n\n::: {.callout-note collapse=\"true\" title=\"Data overview\"}\n::: panel-tabset\n#### Data preview\n\n```{r}\nknitr::kable(head(temps0))\n```\n\n#### Column metadata\n\n| Column        | Type      | Description                                                       | Values                                                                   |\n|------------|------------|-----------------------|-------------------------|\n| `Subject.ID`  | character | Subject identifier where number (1-5) corresponds to neighborhood | 1=Coffelt, 2=Encanto-Palmcroft, 3=Garfield, 4=Thunderhill, 5=Power Ranch |\n| `period`      | character | 4 hour measurement period                                         | weekday, period                                                          |\n| `temperature` | num       | 4 hour average of IET during specified period                     | Celcius                                                                  |\n:::\n:::\n\n::: {.callout-tip collapse=\"true\" title=\"Analysis ideas and hints\"}\n::: panel-tabset\n#### Analysis hints\n\n-   We recommend using functions in the `stringr` package from the tidyverse to parse the strings, particularly `str_sub()` and `str_split_fixed()`.\n\n    -   e.g. If you had a vector `x`, which contains a bunch of 2 character codes and you wanted to extract the first character: `str_sub(x, 1, 1)`\n\n    -   e.g. If you had a vector `x`, which contains information in the format `first-second-third` and you wanted to extract the 1st chunk: `str_split_fixed(x, \"-\", n=3)[,1]`\n\n-   R has some \"counting\" functions such as `length()` and `n()`: how could you get unique counts? Is there a single function that does that?\n\n#### Example questions\n\nUse these questions to develop your own, or answer them as-is. These is no \"single\" or \"correct\" way to answer to these questions, and you can refine or broaden the scope of these questions as needed.\n\n**Bolded** questions have an accompanying figure and code.\n\n------------------------------------------------------------------------\n\nEasier\n\n-   **How many participants were there for each neighborhood in the study?**\n-   On average, which 4-hour measurement period is the warmest? The coolest?\n\nHarder\n\n-   **What was the daily average temperature for each neighborhood during the study period?**\n-   For a specific neighborhood on a certain day, what were all the individual temperatures experienced for each 4-hour measurement period?\n\n#### Example figures\n\n**Easier: How many participants were there for each neighborhood in the study?**\n\n![](project-day-2_files/figs/temps-easy.png){width=\"75%\"}\n\n**Harder: What was the daily average temperature for each neighborhood during the study period?** ![](project-day-2_files/figs/temps-hard.png){width=\"75%\"}\n:::\n:::\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":{"html_document":null},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","number-sections":false,"toc":true,"toc-depth":4,"output-file":"class8.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","editor":"visual","theme":"cosmo","title":"Practicing on Real-World Data","subtitle":"Project Management, Day 2","authors":"Lorrie He, Matthew Sutcliffe"},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":{"html_document":null},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"class8.pdf"},"language":{},"metadata":{"block-headings":true,"editor":"visual","documentclass":"scrreprt","title":"Practicing on Real-World Data","subtitle":"Project Management, Day 2","authors":"Lorrie He, Matthew Sutcliffe"},"extensions":{"book":{}}}}}